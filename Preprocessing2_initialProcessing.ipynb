{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc2a634-e3fa-4e5e-a9c1-46a98cd78613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "from scripts.preprocessing import scale_range, crop_borders, get_best_rotation, histogram_equalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b209e34-db02-4764-913e-23fd480e7c68",
   "metadata": {},
   "source": [
    "# Initial Preprocessing Steps to make images easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a9646d-b52d-4229-b22f-29c02dbe03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### EDIT DIRECTORY VARIABLES AS NEEDED\n",
    "root = \"S:/CheXpert\"\n",
    "source_train_folder_name = \"CheXpert-v1.0 batch 4 (train 3)\"\n",
    "source_test_folder_name = \"CheXpert-v1.0 batch 1 (validate & csv)\"\n",
    "\n",
    "train_filepath = f\"{root}/train_data.csv\"\n",
    "test_filepath = f\"{root}/test_data.csv\"\n",
    "\n",
    "train_folder_name = \"train\"\n",
    "test_folder_name = \"test\"\n",
    "train2_folder_name = \"train2\"\n",
    "test2_folder_name = \"test2\"\n",
    "\n",
    "#####\n",
    "\n",
    "### Instantiate Variables\n",
    "\n",
    "# Source: This is where the raw image files are stored (the next level are patient folders)\n",
    "source_train_root = f\"{root}/{source_train_folder_name}/\"\n",
    "source_test_root  = f\"{root}/{source_test_folder_name}/valid/\"\n",
    "\n",
    "# These are the output roots for file paths being added to the train/test files\n",
    "train_root = f\"{root}/{train_folder_name}/\"\n",
    "test_root = f\"{root}/{test_folder_name}/\"\n",
    "train2_root = f\"{root}/{train2_folder_name}/\"\n",
    "test2_root = f\"{root}/{test2_folder_name}/\"\n",
    "\n",
    "# This is the original root for the train/test csv files\n",
    "base_path = \"CheXpert-v1.0/train/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5da7fa9e-6b1d-46fb-9f6f-a4d8ad97957d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# rows in train_df: 39355\n",
      "# rows in test_df: 202\n"
     ]
    }
   ],
   "source": [
    "### Load the training/validation csvs\n",
    "train_df = pd.read_csv(train_filepath)\n",
    "test_df = pd.read_csv(test_filepath)\n",
    "\n",
    "print(f\"# rows in train_df: {len(train_df)}\")\n",
    "print(f\"# rows in test_df: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e1684-c297-49e6-bf62-af5862f41fa1",
   "metadata": {},
   "source": [
    "## Preprocessing Steps:\n",
    "\n",
    "* Scale the image values to the range [0-255]\n",
    "* Crop out any border regions algorithmically\n",
    "* Resize the training and validation images to 512x512\n",
    "<!-- * Find the 90-degree rotation which is closest to the average of a sample of 1000 x-ray images -->\n",
    "* Convert the array to type uint8 for compatibility with Image\n",
    "* Save the processed image as as jpeg file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45084a08-28de-4823-922b-889b68b2f69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing variables\n",
    "\n",
    "### Value range for scaling image array\n",
    "scale_min = 0\n",
    "scale_max = 255\n",
    "crop_q1_threshold, crop_q3_threshold = np.quantile([i for i in range(scale_min,scale_max)], [0.25, 0.75])\n",
    "\n",
    "### Desired image dimensions for analysis\n",
    "image_height = 512\n",
    "image_width = 512\n",
    "\n",
    "### Threshold for cropping borders\n",
    "threshold_range = (scale_max - scale_min) * 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caf517d1-cc5d-4582-806d-1a0998845584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Find the average training image from a subsample\n",
    "# avg_img_arr = np.zeros((image_height, image_width))\n",
    "\n",
    "# # Online mean computation of a sample of resized and rescaled train X-rays\n",
    "# for i,img_path in enumerate(train_df[\"source_file_path\"].sample(1000), start=1):\n",
    "#     with Image.open(img_path) as img:\n",
    "#         img_arr = np.array(img.resize((image_height, image_width)))\n",
    "#         img_arr = scale_range(img_arr, scale_min, scale_max)\n",
    "#         avg_img_arr = (1 - (1 / i)) * avg_img_arr + (1 / i) * img_arr\n",
    "\n",
    "# avg_img = Image.fromarray(avg_img_arr)\n",
    "# cropped_avg_img_arr = np.array(Image.fromarray(np.array(avg_img)[75:350,75:450]).resize((image_height, image_width)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48a8cd91-174e-4838-a814-913231ca0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Get two versions: both with lowered brightness, one as the regular view and the second cropped to just the lungs\n",
    "# enhancer = ImageEnhance.Brightness(avg_img.convert(\"L\"))\n",
    "# lowBrightness_avg_img_arr = np.array(enhancer.enhance(0.1))\n",
    "# lowBrightness_avg_img_arr = histogram_equalization(lowBrightness_avg_img_arr, scale_min, scale_max, 1)\n",
    "# lowBrightnessCropped_avg_img_arr = np.array(Image.fromarray(np.array(lowBrightness_avg_img_arr)[75:350,75:450]).resize((image_height, image_width)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7daa299b-2dfd-4a1b-acec-26dc5439afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Visualize the mean image\n",
    "# fig, axes = plt.subplots(2,2, figsize=(7,7))\n",
    "# ax = axes.flatten()\n",
    "\n",
    "# ax[0].imshow(avg_img, cmap=\"gray\")\n",
    "# ax[1].imshow(cropped_avg_img_arr, cmap=\"gray\")\n",
    "# ax[2].imshow(lowBrightness_avg_img_arr, cmap=\"gray\")\n",
    "# ax[3].imshow(lowBrightnessCropped_avg_img_arr, cmap=\"gray\")\n",
    "\n",
    "# ax[0].set(title=\"Average Pixel Values\", xticks=[], yticks=[])\n",
    "# ax[1].set(title=\"Cropped Version\", xticks=[], yticks=[])\n",
    "# ax[2].set(title=\"Average Pixel Values,\\nLowered Brightness\", xticks=[], yticks=[])\n",
    "# ax[3].set(title=\"Cropped Version,\\nLowered Brightness\", xticks=[], yticks=[])\n",
    "\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0efa382-c0e0-4a93-aeee-e7cc2861e824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 29.1 s\n",
      "Wall time: 36.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Preprocessing steps for the regular test set\n",
    "input_paths = test_df[\"source_file_path\"]\n",
    "output_paths = test_df[\"test_file_path\"]\n",
    "\n",
    "for i,(input_file_path, output_file_path) in enumerate(zip(input_paths, output_paths)):\n",
    "    with Image.open(input_file_path) as img:\n",
    "        img_arr = np.array(img)\n",
    "        img_arr = scale_range(img_arr, scale_min, scale_max)\n",
    "        img_arr = crop_borders(img_arr, threshold_range, crop_q1_threshold, crop_q3_threshold)\n",
    "        img_arr = np.array(Image.fromarray(img_arr).resize((image_height, image_width), resample=Image.Resampling.BILINEAR))\n",
    "        # img_arr, hm_dist = get_best_rotation(img_arr, lowBrightness_avg_img_arr, lowBrightnessCropped_avg_img_arr)\n",
    "        img = Image.fromarray(img_arr.astype(np.uint8))\n",
    "        img.save(output_file_path, \"JPEG\", quality=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75154011-8d05-41f7-b591-7db8787eecfc",
   "metadata": {},
   "source": [
    "### (RUN THE BELOW CELL ONCE, MAY TAKE A FEW HOURS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc96f417-cfd6-4244-b550-d025c5e4e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing steps for the regular training set \n",
    "input_paths = train_df[\"source_file_path\"]\n",
    "output_paths = train_df[\"train_file_path\"]\n",
    "\n",
    "for i,(input_file_path, output_file_path) in enumerate(zip(input_paths, output_paths)):\n",
    "    with Image.open(input_file_path) as img:\n",
    "        img_arr = np.array(img)\n",
    "        img_arr = scale_range(img_arr, scale_min, scale_max)\n",
    "        img_arr = crop_borders(img_arr, threshold_range, crop_q1_threshold, crop_q3_threshold)\n",
    "        img_arr = np.array(Image.fromarray(img_arr).resize((image_height, image_width), resample=Image.Resampling.BILINEAR))\n",
    "        # img_arr, hm_dist = get_best_rotation(img_arr, lowBrightness_avg_img_arr, lowBrightnessCropped_avg_img_arr)\n",
    "        img = Image.fromarray(img_arr.astype(np.uint8))\n",
    "        img.save(output_file_path, \"JPEG\", quality=90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
