{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc2a634-e3fa-4e5e-a9c1-46a98cd78613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from PIL import Image, ImageEnhance\n",
    "# from scipy.ndimage import convolve\n",
    "from skimage.metrics import structural_similarity\n",
    "\n",
    "from scripts.preprocessing import scale_range, crop_borders, get_best_rotation, histogram_equalization, unsharp_masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b209e34-db02-4764-913e-23fd480e7c68",
   "metadata": {},
   "source": [
    "# Initial Preprocessing Steps to make images easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a9646d-b52d-4229-b22f-29c02dbe03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT DIRECTORY VARIABLES AS NEEDED\n",
    "# --- Main Directory: contains all folders/files\n",
    "root = \"S:/CheXpert/\"\n",
    "# --- This is the original root listed on the csv file paths\n",
    "old_root = \"CheXpert-v1.0/train/\"\n",
    "old_test_root = \"test/\"\n",
    "\n",
    "# --- Input directory variables\n",
    "source_train_root = f\"{root}raw_data/CheXpert-v1.0 batch 4 (train 3)/\"\n",
    "source_valid_root = f\"{root}raw_data/CheXpert-v1.0 batch 1 (validate & csv)/valid/\"\n",
    "source_test_root = f\"{root}raw_data/test/\"\n",
    "train_root = f\"{root}train/\"\n",
    "valid_root = f\"{root}valid/\"\n",
    "test_root = f\"{root}test/\"\n",
    "\n",
    "# --- train/valid/test csv\n",
    "train_filepath = f\"{root}/train_data.csv\"\n",
    "valid_filepath = f\"{root}/valid_data.csv\"\n",
    "test_filepath = f\"{root}/test_data.csv\"\n",
    "\n",
    "# --- Image sizes\n",
    "dims = [224, 384, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45084a08-28de-4823-922b-889b68b2f69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing variables\n",
    "# --- Value range for scaling image array\n",
    "scale_min = 0\n",
    "scale_max = 255\n",
    "crop_q1_threshold, crop_q3_threshold = np.quantile([i for i in range(scale_min,scale_max)], [0.25, 0.75])\n",
    "\n",
    "# --- Threshold for cropping borders (50% chance to cut off any borders)\n",
    "cutoff = 0.5\n",
    "threshold_range = (scale_max - scale_min) * 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5da7fa9e-6b1d-46fb-9f6f-a4d8ad97957d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# rows in train_df: 39358\n",
      "# rows in valid_df: 202\n",
      "# rows in test_df: 518\n"
     ]
    }
   ],
   "source": [
    "# Load the training/validation csvs\n",
    "train_df = pd.read_csv(train_filepath)\n",
    "valid_df = pd.read_csv(valid_filepath)\n",
    "test_df = pd.read_csv(test_filepath)\n",
    "\n",
    "print(f\"# rows in train_df: {len(train_df)}\")\n",
    "print(f\"# rows in valid_df: {len(valid_df)}\")\n",
    "print(f\"# rows in test_df: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "831e0b7c-f508-4ee3-9db9-a23c1097d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pipeline1(img_arr, kernel, he_sigma, scale_min, scale_max):\n",
    "#     \"\"\"Scale the range, sharpen by convolving with a kernel, then equalize the histogram\"\"\"\n",
    "#     output = scale_range(img_arr, scale_min, scale_max)\n",
    "#     output = convolve(output, kernel)\n",
    "#     output = histogram_equalization(output, scale_min, scale_max, he_sigma)\n",
    "#     return output\n",
    "\n",
    "def pipeline2(img_arr, weight, usm_sigma, he_sigma, scale_min, scale_max):\n",
    "    \"\"\"Scale the range, sharpen via unsharp masking, then equalize the histogram\"\"\"\n",
    "    output = unsharp_masking(img_arr, usm_sigma, weight, scale_min, scale_max)\n",
    "    output = histogram_equalization(output, scale_min, scale_max, he_sigma)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c3aede3-c271-4c11-ab3a-72559ec378ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image enhancement variables\n",
    "he_sigma = 5\n",
    "usm_sigma = 10\n",
    "weight = 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e1684-c297-49e6-bf62-af5862f41fa1",
   "metadata": {},
   "source": [
    "## Preprocessing Steps:\n",
    "\n",
    "* Scale the image values to the range [0-255]\n",
    "<!-- * Crop out any border regions algorithmically -->\n",
    "* Resize the training and validation images to (224x224), (384x284), (512x512)\n",
    "<!-- * Find the 90-degree rotation which is closest to the average of a sample of 1000 x-ray images -->\n",
    "* Convert the array to type uint8 for compatibility with Image\n",
    "* Save the processed image as as jpeg file\n",
    "\n",
    "### Preprocessing steps for enhanced images\n",
    "\n",
    "* Scale the image values to the range [0-255]\n",
    "<!-- * Crop out any border regions algorithmically -->\n",
    "* Resize the training and validation images to (224x224), (384x284), (512x512)\n",
    "<!-- * Find the 90-degree rotation which is closest to the average of a sample of 1000 x-ray images -->\n",
    "* Sharpen the image using unsharp masking\n",
    "* Equalize the histogram to increase contrast\n",
    "* Convert the array to type uint8 for compatibility with Image\n",
    "* Save the processed image as as jpeg file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0efa382-c0e0-4a93-aeee-e7cc2861e824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 22s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Preprocessing steps for the valid set\n",
    "output_df = valid_df.copy()\n",
    "\n",
    "input_paths = output_df[\"source_file_path\"]\n",
    "output_paths_list = [output_df[f\"base{str(dim)}_file_path\"] for dim in dims]\n",
    "output_paths_list2 = [output_df[f\"base{str(dim)}_file_path\"].str[:-4] + \"_usm.jpg\" for dim in dims]\n",
    "\n",
    "for output_paths,output_paths2,dim in zip(output_paths_list, output_paths_list2, dims):\n",
    "    for i,(input_file_path, output_file_path, output_file_path2) in enumerate(zip(input_paths, output_paths, output_paths2)):\n",
    "        with Image.open(input_file_path) as img:\n",
    "            img_arr = np.array(Image.fromarray(img_arr).resize((dim, dim), resample=Image.Resampling.BILINEAR))\n",
    "            img = Image.fromarray(scale_range(img_arr, scale_min, scale_max).astype(np.uint8))\n",
    "            img.save(output_file_path, \"JPEG\", quality=90)\n",
    "            #\n",
    "            img_arr2 = pipeline2(img_arr, weight, usm_sigma, he_sigma, scale_min, scale_max)\n",
    "            img2 = Image.fromarray(img_arr2.astype(np.uint8))\n",
    "            img2.save(output_file_path2, \"JPEG\", quality=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70b2ed52-5773-4315-9520-ee7ef28e6818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 26s\n",
      "Wall time: 3min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Preprocessing steps for the test set\n",
    "output_df = test_df.copy()\n",
    "\n",
    "input_paths = output_df[\"source_file_path\"]\n",
    "output_paths_list = [output_df[f\"base{str(dim)}_file_path\"] for dim in dims]\n",
    "output_paths_list2 = [output_df[f\"base{str(dim)}_file_path\"].str[:-4] + \"_usm.jpg\" for dim in dims]\n",
    "\n",
    "for output_paths,output_paths2,dim in zip(output_paths_list, output_paths_list2, dims):\n",
    "    for i,(input_file_path, output_file_path, output_file_path2) in enumerate(zip(input_paths, output_paths, output_paths2)):\n",
    "        with Image.open(input_file_path) as img:\n",
    "            img_arr = np.array(img)\n",
    "            img_arr = np.array(Image.fromarray(img_arr).resize((dim, dim), resample=Image.Resampling.BILINEAR))\n",
    "            img = Image.fromarray(scale_range(img_arr, scale_min, scale_max).astype(np.uint8))\n",
    "            img.save(output_file_path, \"JPEG\", quality=90)\n",
    "            #\n",
    "            img_arr2 = pipeline2(img_arr, weight, usm_sigma, he_sigma, scale_min, scale_max)\n",
    "            img2 = Image.fromarray(img_arr2.astype(np.uint8))\n",
    "            img2.save(output_file_path2, \"JPEG\", quality=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75154011-8d05-41f7-b591-7db8787eecfc",
   "metadata": {},
   "source": [
    "### (RUN THE BELOW CELL ONCE, MAY TAKE A FEW HOURS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc96f417-cfd6-4244-b550-d025c5e4e83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5h 52s\n",
      "Wall time: 6h 27min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Preprocessing steps for the train set\n",
    "output_df = train_df.copy()\n",
    "\n",
    "input_paths = output_df[\"source_file_path\"]\n",
    "output_paths_list = [output_df[f\"base{str(dim)}_file_path\"] for dim in dims]\n",
    "output_paths_list2 = [output_df[f\"base{str(dim)}_file_path\"].str[:-4] + \"_usm.jpg\" for dim in dims]\n",
    "\n",
    "for output_paths,output_paths2,dim in zip(output_paths_list, output_paths_list2, dims):\n",
    "    for i,(input_file_path, output_file_path, output_file_path2) in enumerate(zip(input_paths, output_paths, output_paths2)):\n",
    "        with Image.open(input_file_path) as img:\n",
    "            img_arr = np.array(img)\n",
    "            img_arr = np.array(Image.fromarray(img_arr).resize((dim, dim), resample=Image.Resampling.BILINEAR))\n",
    "            img = Image.fromarray(scale_range(img_arr, scale_min, scale_max).astype(np.uint8))\n",
    "            img.save(output_file_path, \"JPEG\", quality=90)\n",
    "            #\n",
    "            img_arr2 = pipeline2(img_arr, weight, usm_sigma, he_sigma, scale_min, scale_max)\n",
    "            img2 = Image.fromarray(img_arr2.astype(np.uint8))\n",
    "            img2.save(output_file_path2, \"JPEG\", quality=90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
